{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start to collect data from the article. ~ 100 articles as a small starting point?\n",
    "2. Set up a database to store the articles (instead of just a python data structure in memory)\n",
    "3. Draw up a workflow for the app and sketch out functions, how things connect, plans for each and start up git for it. (you need to get used to the git functionality stuff.)\n",
    "4. Start to commit to it and write some tests for the functions to include in your test driven development. For now, just put everything in one script. \n",
    "5. In parallel start to do some OOP once you get the classes set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = (\"https://www.axios.com/facebook-employees-stage-virtual-walkout-\"\n",
    "    \"7f28483e-d59c-4d5d-b4b7-891113b56233.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(URL: str):\n",
    "    return requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soupify_webpage(page, parser_type = 'html.parser'):\n",
    "    return BeautifulSoup(page.content, parser_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_main_article(soup):\n",
    "    return soup.find('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_main_text(main_article, class_type = None):\n",
    "    if class_type is None:\n",
    "        class_type = 'b0w77w-0 jctzOA gtm-story-text p mt-12 mb-20 sm:mt-20'\n",
    "    else:\n",
    "        class_type = class_type\n",
    "    article = soup.find('div', class_=class_type).text\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_main_headline(soup):\n",
    "    return soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_main_authors(main_article):\n",
    "    authors_html = main_article.find('div', class_='truncate').find_all('a')\n",
    "    authors = [authors_html[ind].text for ind in range(len(authors_html))]\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_main_tags(main_article):\n",
    "    return main_article.find('div').a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_urls(soup):\n",
    "    latest_stories = soup.find('div',id='maincontent').find('section').find_all('a', class_='title-link')\n",
    "    return [latest_stories[ind]['href'] for ind in range(len(latest_stories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def get_date():\n",
    "    return str(date.today().year) + '/' + str(date.today().month) + '/' + str(date.today().day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(article_text):\n",
    "    return len(article_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = get_webpage(URL)\n",
    "soup = soupify_webpage(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_article = isolate_main_article(soup)\n",
    "main_tags = isolate_main_tags(main_article)\n",
    "main_headline = isolate_main_headline(soup)\n",
    "main_authors = isolate_main_authors(main_article)\n",
    "main_text = isolate_main_text(main_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Headline of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = article.h1.text\n",
    "headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Text of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = article.find('div', class_='b0w77w-0 jctzOA gtm-story-text p mt-12 mb-20 sm:mt-20').text\n",
    "article_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Section Tags of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = article.find('div').a['href'][1:]\n",
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Author of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = article.find('div', class_='truncate').find_all('a')\n",
    "author = []\n",
    "\n",
    "for ind in range(len(a_list)):\n",
    "    author.append(a_list[ind].text)\n",
    "    \n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the class string match in other articles as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://www.axios.com/trump-putin-g7-phone-call-7820750a-9bc3-4696-898e-f85bb012005b.html'\n",
    "page2 = requests.get(URL2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article2 = soup2.find('article')\n",
    "print(article2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline2 = article2.h1.text\n",
    "headline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article2.find('div', class_='b0w77w-0 jctzOA gtm-story-text p mt-12 mb-20 sm:mt-20').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract links to URLs for latest stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.axios.com/'\n",
    "main_page = get_webpage(main_url)\n",
    "main_soup = soupify_webpage(main_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_stories = main_soup.find('div',id='maincontent').find('section').find_all('a', class_='title-link hover:text-accent-blue-shade')\n",
    "url_latest_stories = [latest_stories[ind]['href'] for ind in range(len(latest_stories))]\n",
    "url_latest_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_urls(soup):\n",
    "    latest_stories = soup.find('div',id='maincontent').find('section').find_all('a', class_='title-link')\n",
    "    return [latest_stories[ind]['href'] for ind in range(len(latest_stories))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latest_urls(main_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_='time-rubric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_='time-rubric')[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use dates to find older stories\n",
    "https://www.axios.com/technology/2020/05/30\n",
    "format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections in Axios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.axios.com/'\n",
    "page = get_webpage(URL)\n",
    "soup = soupify_webpage(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['politics-policy',\n",
    "            'technology',\n",
    "            'economy-business',\n",
    "            'health',\n",
    "            'world',\n",
    "            'energy-environment',\n",
    "            'science',\n",
    "            'sports']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def get_date():\n",
    "    return str(date.today().year) + '/' + str(date.today().month) + '/' + str(date.today().day)\n",
    "\n",
    "get_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "main_url = 'https://www.axios.com/'\n",
    "main_page = get_webpage(main_url)\n",
    "main_soup = soupify_webpage(main_page)\n",
    "print('Got the main page')\n",
    "\n",
    "main_text_db = []\n",
    "\n",
    "for url in get_latest_urls(main_soup):\n",
    "    time.sleep(5)\n",
    "    page = get_webpage(url)\n",
    "    soup = soupify_webpage(page)\n",
    "    print('Got another page')\n",
    "    main_article = isolate_main_article(soup)\n",
    "    main_tags = isolate_main_tags(main_article)\n",
    "    main_headline = isolate_main_headline(soup)\n",
    "    main_authors = isolate_main_authors(main_article)\n",
    "    main_text = isolate_main_text(main_article)\n",
    "    \n",
    "    main_text_db.append(main_text)\n",
    "    \n",
    "    #print(f'Headline: {main_headline}')\n",
    "    #print(f'Main Authors: {main_authors}')\n",
    "    #print(f'Main Text: {main_text}')\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(article_text):\n",
    "    return len(article_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://www.axios.com/health/' + get_date()\n",
    "page = get_webpage(test_url)\n",
    "soup = soupify_webpage(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a', class_='gtm-content-click title-link')[0]['href']\n",
    "#return [latest_stories[ind]['href'] for ind in range(len(latest_stories))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url_by_section(url):\n",
    "    url = url + get_date()\n",
    "    page = get_webpage(url)\n",
    "    soup = soupify_webpage(page)\n",
    "    \n",
    "    all_urls = soup.find_all('a', class_='gtm-content-click title-link')\n",
    "    return [all_urls[url_num]['href'] for url_num in range(len(all_urls))]\n",
    "\n",
    "find_url_by_section('https://www.axios.com/health/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status_code(page):\n",
    "    return page.status_code\n",
    "\n",
    "check_status_code(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('axios_news.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "#Create table - Articles\n",
    "articles_table = \"\"\"CREATE TABLE IF NOT EXISTS Articles (\n",
    "                    Section STRING,\n",
    "                    Hyperlink STRING,\n",
    "                    ArticleID INTEGER PRIMARY KEY,\n",
    "                    MainText STRING,\n",
    "                    Headline STRING,\n",
    "                    PubDate STRING,\n",
    "                    WordCount INTEGER);\"\"\"\n",
    "c.execute(articles_table)\n",
    "\n",
    "#Create table - Authors\n",
    "authors_table = \"\"\"CREATE TABLE IF NOT EXISTS Authors (\n",
    "                    Name STRING,\n",
    "                    Section STRING,\n",
    "                    Position STRING,\n",
    "                    Description STRING,\n",
    "                    Hyperlink STRING,\n",
    "                    AuthorID INTEGER PRIMARY KEY,\n",
    "                    ArticleID INTEGER,\n",
    "                    FOREIGN KEY(ArticleID) REFERENCES Articles(ArticleID));\"\"\"\n",
    "c.execute(authors_table)\n",
    "\n",
    "#Create table - ArticleAuthors\n",
    "articleauthors_table = \"\"\"CREATE TABLE IF NOT EXISTS ArticleAuthors (\n",
    "                    ArticleID INTEGER,\n",
    "                    AuthorID INTEGER);\"\"\"\n",
    "c.execute(articleauthors_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def create_connection(db_filename):\n",
    "    return sqlite3.connect(db_filename)\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    c = conn.cursor()\n",
    "    c.execute(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_filename = 'axios_news.db'\n",
    "\n",
    "articles_table = \"\"\"CREATE TABLE IF NOT EXISTS Articles (\n",
    "                    Section STRING,\n",
    "                    Hyperlink STRING,\n",
    "                    ArticleID INTEGER PRIMARY KEY,\n",
    "                    MainText STRING,\n",
    "                    Headline STRING,\n",
    "                    PubDate STRING,\n",
    "                    WordCount INTEGER);\"\"\"\n",
    "\n",
    "authors_table = \"\"\"CREATE TABLE IF NOT EXISTS Authors (\n",
    "                    Name STRING,\n",
    "                    Section STRING,\n",
    "                    Position STRING,\n",
    "                    Description STRING,\n",
    "                    Hyperlink STRING,\n",
    "                    AuthorID INTEGER PRIMARY KEY,\n",
    "                    ArticleID INTEGER,\n",
    "                    FOREIGN KEY(ArticleID) REFERENCES Articles(ArticleID));\"\"\"\n",
    "\n",
    "articleauthors_table = \"\"\"CREATE TABLE IF NOT EXISTS ArticleAuthors (\n",
    "                    ArticleID INTEGER,\n",
    "                    AuthorID INTEGER);\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be mindful of SQL Injection attacks and construct parameter queries when adding the files. Even if it comes from\n",
    "#your API. Don't get Sloppy.\n",
    "\n",
    "conn = create_connection(db_filename)\n",
    "create_table(conn, articles_table)\n",
    "create_table(conn, authors_table)\n",
    "create_table(conn, articleauthors_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
